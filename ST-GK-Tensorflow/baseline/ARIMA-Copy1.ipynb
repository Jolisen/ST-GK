{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd34a3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "import numpy.linalg as la\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "import os\n",
    "\n",
    "def preprocess_data(data, time_len, rate, seq_len, pre_len):\n",
    "    data1 = np.mat(data)\n",
    "    train_size = int(time_len * rate)+6\n",
    "    train_data = data1[0:train_size]\n",
    "    test_data = data1[train_size:time_len]\n",
    "    return train_data, test_data\n",
    "\n",
    "\n",
    "###### evaluation ######\n",
    "def evaluation(a,b):\n",
    "    rmse = math.sqrt(mean_squared_error(a,b))\n",
    "    mae = mean_absolute_error(a, b)\n",
    "    F_norm = la.norm(a-b,'fro')/la.norm(a,'fro')\n",
    "    r2 = 1-((a-b)**2).sum()/((a-a.mean())**2).sum()\n",
    "    var = 1-(np.var(a-b))/np.var(a)\n",
    "    return rmse, mae, 1-F_norm, r2, var\n",
    "def evaluation1(a,b):\n",
    "    rmse = math.sqrt(mean_squared_error(a,b))\n",
    "    mae = mean_absolute_error(a, b)\n",
    "    return rmse, mae\n",
    "def evaluation2(a,b):\n",
    "    F_norm = la.norm(a-b)/la.norm(a)\n",
    "    r2 = 1-((a-b)**2).sum()/((a-a.mean())**2).sum()\n",
    "    var = 1-(np.var(a-b))/np.var(a)\n",
    "    return 1-F_norm, r2, var\n",
    "\n",
    "path = r'data/3611817550_feature_matrix_X.xlsx'\n",
    "data = pd.read_excel(path)\n",
    "\n",
    "############# normalization ###############\n",
    "price_frame = data\n",
    "min_max_scaler = preprocessing.MinMaxScaler(feature_range=(0, 1), copy=True)\n",
    "data = min_max_scaler.fit_transform(price_frame)\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "time_len = data.shape[0]\n",
    "num_nodes = data.shape[1]\n",
    "train_rate = 0.8\n",
    "seq_len = 5\n",
    "pre_len = 1\n",
    "train_data, test_data = preprocess_data(data, time_len, train_rate, seq_len, pre_len)\n",
    "train_data = pd.DataFrame(train_data)\n",
    "\n",
    "\n",
    "out = 'out/ARIMA'\n",
    "path1 = 'precipitationARIMA_%r_seq%r_pre'%(seq_len,pre_len)\n",
    "path = os.path.join(out,path1)\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e35521c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jolisen/anaconda3/envs/tensorflow/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py:472: FutureWarning: \n",
      "statsmodels.tsa.arima_model.ARMA and statsmodels.tsa.arima_model.ARIMA have\n",
      "been deprecated in favor of statsmodels.tsa.arima.model.ARIMA (note the .\n",
      "between arima and model) and\n",
      "statsmodels.tsa.SARIMAX. These will be removed after the 0.12 release.\n",
      "\n",
      "statsmodels.tsa.arima.model.ARIMA makes use of the statespace framework and\n",
      "is both well tested and maintained.\n",
      "\n",
      "To silence this warning and continue using ARMA and ARIMA until they are\n",
      "removed, use:\n",
      "\n",
      "import warnings\n",
      "warnings.filterwarnings('ignore', 'statsmodels.tsa.arima_model.ARMA',\n",
      "                        FutureWarning)\n",
      "warnings.filterwarnings('ignore', 'statsmodels.tsa.arima_model.ARIMA',\n",
      "                        FutureWarning)\n",
      "\n",
      "  warnings.warn(ARIMA_DEPRECATION_WARN, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4200, 30)\n",
      "(4200, 30)\n",
      "arima_rmse:0.41959796353645124 arima_mae:0.26607248482801993 arima_acc:0.9065766562953074 arima_r2:0.9106019102724339 arima_var:0.9106211995275256\n"
     ]
    }
   ],
   "source": [
    "rng = pd.date_range('2022/8/25 13:00:00', periods=21026, freq='30min')\n",
    "a1 = pd.DatetimeIndex(rng)\n",
    "rmse,mae,acc,r2,var,pred,ori = [],[],[],[],[],[],[]\n",
    "for i in range(30):\n",
    "    ts = data.iloc[:,i]\n",
    "#     ts_log=np.log(ts)    \n",
    "#     ts_log=np.array(ts_log)\n",
    "#     where_are_inf = np.isinf(ts_log)\n",
    "#     ts_log[where_are_inf] = 0\n",
    "\n",
    "    ts_log = pd.Series(ts)\n",
    "    ts_log.index = a1\n",
    "    \n",
    "    \n",
    "    model = ARIMA(ts_log,order=[1,0,0])\n",
    "    properModel = model.fit()\n",
    "    predict_ts = properModel.predict(16826, dynamic=True)\n",
    "    #log_recover = np.exp(predict_ts)\n",
    "#     ts = ts[predict_ts.index]\n",
    "    pre = np.array(np.transpose(np.mat(predict_ts)))\n",
    "    pre = pre.repeat(pre_len ,axis=1)\n",
    "    pred.append(pre)\n",
    "    \n",
    "    \n",
    "result1 = np.array(pred)\n",
    "result1 = np.reshape(result1, [num_nodes,-1])\n",
    "result1 = np.transpose(result1)\n",
    "print(result1.shape)\n",
    "testY1 = np.array(test_data)\n",
    "testY1 = np.reshape(testY1, [-1,num_nodes])\n",
    "print(testY1.shape)\n",
    "############## renormalization ###############\n",
    "test_label1 = min_max_scaler.inverse_transform(test_data)\n",
    "test_output1 = min_max_scaler.inverse_transform(result1)\n",
    "\n",
    "rmse1, mae1 = evaluation1(test_label1, test_output1)\n",
    "#rmse1, mae1, acc1,r2,var = evaluation(testY1, result1)\n",
    "acc1,r2,var = evaluation2(testY1, result1)\n",
    "\n",
    "\n",
    "print('arima_rmse:%r'%rmse1,\n",
    "      'arima_mae:%r'%mae1,\n",
    "      'arima_acc:%r'%acc1,\n",
    "      'arima_r2:%r'%r2,\n",
    "      'arima_var:%r'%var)\n",
    "result = pd.DataFrame(test_output1)\n",
    "testYY = pd.DataFrame(test_label1)\n",
    "result.to_csv(path+'/test_prediction.csv',index = False,header = False)\n",
    "testYY.to_csv(path+'/test_true.csv',index = False,header = False)\n",
    "evalution = []\n",
    "evalution.append(rmse1)\n",
    "evalution.append(mae1)\n",
    "evalution.append(acc1)\n",
    "evalution.append(r2)\n",
    "evalution.append(var)\n",
    "evalution = pd.DataFrame(evalution)\n",
    "evalution.to_csv(path+'/evalution.csv',index=False,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f470ba02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
